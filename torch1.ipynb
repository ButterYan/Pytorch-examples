{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch常见操作示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（一）张量的创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n",
      "tensor([3, 4])\n",
      "tensor([4, 5])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor(4)\n",
    "b=torch.tensor([3,4])\n",
    "c=torch.tensor([4,5],dtype=int)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.]])\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]]])\n",
      "tensor([[4.3700, 4.3700, 4.3700, 4.3700],\n",
      "        [4.3700, 4.3700, 4.3700, 4.3700],\n",
      "        [4.3700, 4.3700, 4.3700, 4.3700]])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7])\n",
      "tensor([1.0000, 1.8750, 2.7500, 3.6250, 4.5000, 5.3750, 6.2500, 7.1250, 8.0000])\n"
     ]
    }
   ],
   "source": [
    "print(torch.zeros(3,3))\n",
    "print(torch.ones(3,3))\n",
    "print(torch.eye(3,2))\n",
    "print(torch.empty(3,2,2))\n",
    "print(torch.full((3,4),4.37))\n",
    "print(torch.arange(1,8,1))\n",
    "print(torch.linspace(1,8,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from_numpy与as_tensor会将np数据与torch数据内容共享，改变一个另一个自动改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[ 1,  2],\n",
      "        [ 3, -4]], dtype=torch.int32)\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "a_np=np.array([[1,2],[3,4]])\n",
    "a_tc=torch.from_numpy(a_np)\n",
    "print(a_np)\n",
    "print(a_tc)\n",
    "a_np[1,1]=-4\n",
    "print(a_tc)\n",
    "\n",
    "b=torch.as_tensor([1,2,3])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4599, 0.5329],\n",
      "         [0.5190, 0.1544],\n",
      "         [0.9084, 0.5454],\n",
      "         [0.2667, 0.7096]],\n",
      "\n",
      "        [[0.6792, 0.8754],\n",
      "         [0.4951, 0.0940],\n",
      "         [0.7127, 0.9170],\n",
      "         [0.1040, 0.5811]]])\n",
      "tensor([[-1.9252,  0.4133, -0.4730,  0.3334],\n",
      "        [-0.1812, -0.2681,  0.5141,  0.7564]])\n",
      "tensor([-1.7130,  5.3427,  8.0321, 16.5173, 21.1972, 24.0742])\n",
      "tensor([0, 6, 5, 3, 2, 7, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "print(torch.rand(2,4,2))\n",
    "print(torch.randn(2,4))\n",
    "print(torch.normal(mean=torch.arange(0,30.0,5),std=torch.tensor(3.0)))\n",
    "print(torch.randperm(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（二）张量的类型与转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.DoubleTensor\n",
      "torch.HalfTensor\n",
      "torch.ByteTensor\n",
      "torch.CharTensor\n",
      "torch.ShortTensor\n",
      "torch.IntTensor\n",
      "torch.LongTensor\n",
      "torch.LongTensor\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(torch.FloatTensor(2,3).type()) #构建一个2*3 Float类型的张量\n",
    "print(torch.DoubleTensor(2,3).type()) #构建一个2*3 Double类型的张量\n",
    "print(torch.HalfTensor (2,3).type()) #构建一个2*3 HalfTenso类型的张量\n",
    "print(torch.ByteTensor(2,3).type()) #构建一个2*3 Byte类型的张量\n",
    "print(torch.CharTensor(2,3).type()) #构建一个2*3 Char类型的张量\n",
    "print(torch.ShortTensor(2,3).type()) #构建一个2*3 Short类型的张量\n",
    "print(torch.IntTensor(2,3).type()) #构建一个2*3 Int类型的张量\n",
    "print(torch.LongTensor(2,3).type()) #构建一个2*3 Long类型的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([1,2])\n",
    "print(a.type())\n",
    "b=torch.randn(2, 2)\n",
    "print(b.type())\n",
    "a2=a.float()\n",
    "print(a2.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（三）张量的操作与运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "小数处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4362,  0.1993,  1.2681],\n",
      "        [-0.2199, -0.4661, -0.1924]])\n",
      "tensor([[-0., 0., 1.],\n",
      "        [-0., -0., -0.]])\n",
      "tensor([[-0.4362,  0.1993,  0.2681],\n",
      "        [-0.2199, -0.4661, -0.1924]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.randn(2,3)\n",
    "print(a)\n",
    "print(a.trunc())\n",
    "print(a.frac())\n",
    "#还有round,ceil,floor函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_后缀会更新tensor对象的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3],\n",
      "        [2, 4]])\n",
      "tensor([[ 1,  9],\n",
      "        [ 4, 16]])\n",
      "tensor([[ 1,  9],\n",
      "        [ 4, 16]])\n",
      "tensor([[1, 3],\n",
      "        [2, 4]])\n",
      "tensor([[ 1,  9],\n",
      "        [ 4, 16]])\n",
      "tensor([[ 1,  9],\n",
      "        [ 4, 16]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[1,3],[2,4]])\n",
    "print(a)\n",
    "print(torch.pow(a,2))\n",
    "print(a.pow(2))\n",
    "print(a)\n",
    "print(a.pow_(2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([2, 4]),\n",
      "indices=tensor([1, 1]))\n",
      "tensor([2, 4])\n",
      "tensor([1, 1])\n",
      "tensor([[1, 3],\n",
      "        [3, 4]])\n",
      "tensor([[ True, False],\n",
      "        [False,  True]])\n",
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "torch.return_types.topk(\n",
      "values=tensor([6, 5, 4, 3, 2]),\n",
      "indices=tensor([5, 4, 3, 2, 1]))\n",
      "tensor([-1.0000,  0.1000, -0.0500, -0.1000])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[1,3],[2,4]])\n",
    "b=torch.tensor([[1,2],[3,4]])\n",
    "print(torch.max(a,0))\n",
    "print(torch.amax(a,0))\n",
    "print(torch.argmax(a,0))\n",
    "print(torch.maximum(a,b))\n",
    "print(torch.eq(a,b))\n",
    "c=torch.arange(1,7,1)\n",
    "print(c)\n",
    "print(torch.topk(c,5))\n",
    "b=torch.tensor([-1.71,0.17,-0.05,-0.1])\n",
    "print(torch.clamp(b,min=-1,max=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性代数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0504, 0.7945],\n",
      "         [0.4009, 0.4715],\n",
      "         [0.9701, 0.4135]],\n",
      "\n",
      "        [[0.6097, 0.8286],\n",
      "         [0.9633, 0.3766],\n",
      "         [0.2590, 0.0220]]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[[0.0504, 0.7945],\n",
      "         [0.6097, 0.8286]],\n",
      "\n",
      "        [[0.4009, 0.4715],\n",
      "         [0.9633, 0.3766]],\n",
      "\n",
      "        [[0.9701, 0.4135],\n",
      "         [0.2590, 0.0220]]])\n",
      "tensor(5)\n",
      "tensor([[ 7, 15],\n",
      "        [10, 22]])\n",
      "tensor(14)\n",
      "torch.return_types.qr(\n",
      "Q=tensor([[-0.4472, -0.8944],\n",
      "        [-0.8944,  0.4472]]),\n",
      "R=tensor([[-2.2361, -4.9193],\n",
      "        [ 0.0000, -0.8944]]))\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[1,3],[2,4]])\n",
    "b=torch.rand(2,3,2)\n",
    "print(b)\n",
    "print(a.T)\n",
    "print(torch.transpose(b,0,1))\n",
    "print(torch.trace(a))\n",
    "print(torch.matmul(a,a))   #矩阵乘法\n",
    "print(torch.dot(a[1,:],a[0,:]))\n",
    "print(torch.qr(a.float()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量的索引与提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([2, 4])\n",
      "tensor([[0.5291, 0.0588, 0.8209, 0.3188],\n",
      "        [0.2909, 0.1093, 0.5630, 0.1545],\n",
      "        [0.2750, 0.8830, 0.9339, 0.9807]])\n",
      "tensor([[0.5291, 0.0588, 0.8209, 0.3188],\n",
      "        [0.2750, 0.8830, 0.9339, 0.9807]])\n",
      "tensor([[0.5291, 0.8209],\n",
      "        [0.2909, 0.5630],\n",
      "        [0.2750, 0.9339]])\n",
      "tensor([[1, 1],\n",
      "        [4, 3]])\n",
      "tensor([[1, 1, 1],\n",
      "        [4, 3, 3]])\n",
      "tensor([0.5877, 0.0818, 0.9653, 0.9124, 0.1005])\n",
      "tensor([0.5877, 0.0818, 0.1005])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[1,3],[2,4]])\n",
    "b=torch.tensor([1,2,3,4])\n",
    "print(a[0,0].item())     #只能提取标量的内容\n",
    "print(torch.take(b,torch.tensor([1,3])))  #b将被看作一维\n",
    "x=torch.rand(3,4)\n",
    "print(x)\n",
    "print(torch.index_select(x,0,torch.tensor([0,2])))\n",
    "print(torch.index_select(x,1,torch.tensor([0,2])))\n",
    "t = torch.tensor([[1, 2], [3, 4]])\n",
    "print(torch.gather(t, 1, torch.tensor([[0,0], [1, 0]])))\n",
    "print(torch.gather(t, 1, torch.tensor([[0, 0,0], [1, 0,0]])))\n",
    "x=torch.rand(5)\n",
    "print(x)\n",
    "print(torch.masked_select(x,torch.tensor([True,True,False,False,True])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（四）张量的拼拆与变形"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "改变形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([12])\n",
      "torch.Size([4, 3])\n",
      "tensor([[0.8550, 0.4121, 0.0643, 0.5459],\n",
      "        [0.7993, 0.9838, 0.9265, 0.3651],\n",
      "        [0.5090, 0.1634, 0.6606, 0.8551]])\n",
      "torch.Size([4, 3])\n",
      "tensor([[[0.8550, 0.4121, 0.0643, 0.5459, 0.7993, 0.9838, 0.9265, 0.3651,\n",
      "          0.5090, 0.1634, 0.6606, 0.8551]]])\n",
      "tensor([[[0.8550]],\n",
      "\n",
      "        [[0.4121]],\n",
      "\n",
      "        [[0.0643]],\n",
      "\n",
      "        [[0.5459]],\n",
      "\n",
      "        [[0.7993]],\n",
      "\n",
      "        [[0.9838]],\n",
      "\n",
      "        [[0.9265]],\n",
      "\n",
      "        [[0.3651]],\n",
      "\n",
      "        [[0.5090]],\n",
      "\n",
      "        [[0.1634]],\n",
      "\n",
      "        [[0.6606]],\n",
      "\n",
      "        [[0.8551]]])\n",
      "tensor([[[0.8550],\n",
      "         [0.4121],\n",
      "         [0.0643],\n",
      "         [0.5459],\n",
      "         [0.7993],\n",
      "         [0.9838],\n",
      "         [0.9265],\n",
      "         [0.3651],\n",
      "         [0.5090],\n",
      "         [0.1634],\n",
      "         [0.6606],\n",
      "         [0.8551]]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(3,4)\n",
    "print(a.shape)\n",
    "a=a.view([2,2,3])\n",
    "print(a.shape)\n",
    "a=a.view(12)\n",
    "print(a.shape)\n",
    "a=a.view([4,-1])\n",
    "print(a.shape)\n",
    "print(torch.reshape(a,[3,4]))\n",
    "print(a.size())\n",
    "print(torch.reshape(a,[1,1,-1]))\n",
    "print(torch.reshape(a,[-1,1,1]))\n",
    "print(torch.reshape(a,[1,-1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并：stack会增加一个维度，cat不会"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6902, 0.5274, 0.1256],\n",
      "        [0.1883, 0.8033, 0.9867]])\n",
      "tensor([[0.6902, 0.5274, 0.1256],\n",
      "        [0.1883, 0.8033, 0.9867],\n",
      "        [0.6902, 0.5274, 0.1256],\n",
      "        [0.1883, 0.8033, 0.9867],\n",
      "        [0.6902, 0.5274, 0.1256],\n",
      "        [0.1883, 0.8033, 0.9867]])\n",
      "tensor([[0.6902, 0.5274, 0.1256, 0.6902, 0.5274, 0.1256, 0.6902, 0.5274, 0.1256],\n",
      "        [0.1883, 0.8033, 0.9867, 0.1883, 0.8033, 0.9867, 0.1883, 0.8033, 0.9867]])\n",
      "tensor([[[0.6902, 0.5274, 0.1256],\n",
      "         [0.1883, 0.8033, 0.9867]],\n",
      "\n",
      "        [[0.6902, 0.5274, 0.1256],\n",
      "         [0.1883, 0.8033, 0.9867]],\n",
      "\n",
      "        [[0.6902, 0.5274, 0.1256],\n",
      "         [0.1883, 0.8033, 0.9867]]])\n",
      "tensor([[[0.6902, 0.5274, 0.1256],\n",
      "         [0.6902, 0.5274, 0.1256],\n",
      "         [0.6902, 0.5274, 0.1256]],\n",
      "\n",
      "        [[0.1883, 0.8033, 0.9867],\n",
      "         [0.1883, 0.8033, 0.9867],\n",
      "         [0.1883, 0.8033, 0.9867]]])\n",
      "tensor([[[0.6902, 0.6902, 0.6902],\n",
      "         [0.5274, 0.5274, 0.5274],\n",
      "         [0.1256, 0.1256, 0.1256]],\n",
      "\n",
      "        [[0.1883, 0.1883, 0.1883],\n",
      "         [0.8033, 0.8033, 0.8033],\n",
      "         [0.9867, 0.9867, 0.9867]]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(2,3)\n",
    "print(a)\n",
    "print(torch.cat((a,a,a),0))\n",
    "print(torch.cat((a,a,a),1))\n",
    "print(torch.stack((a,a,a),0))\n",
    "print(torch.stack((a,a,a),1))\n",
    "print(torch.stack((a,a,a),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分块：chunk用于平均分块，第二个参数为平均分为几块，spilt不平均分，第二个参数向量表示每一块的行数；第三个参数均为分块维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.7043, 0.6343, 0.3183, 0.1325],\n",
      "         [0.8560, 0.5837, 0.7610, 0.5017],\n",
      "         [0.0836, 0.1199, 0.6244, 0.4331]],\n",
      "\n",
      "        [[0.3159, 0.5753, 0.1571, 0.7462],\n",
      "         [0.4330, 0.7616, 0.3375, 0.2553],\n",
      "         [0.4162, 0.1262, 0.4016, 0.1169]]]), tensor([[[0.1288, 0.9278, 0.9681, 0.4022],\n",
      "         [0.2588, 0.1727, 0.5065, 0.4860],\n",
      "         [0.4261, 0.2434, 0.5032, 0.9790]],\n",
      "\n",
      "        [[0.9836, 0.0587, 0.5013, 0.2730],\n",
      "         [0.7209, 0.9671, 0.6290, 0.7841],\n",
      "         [0.4790, 0.7242, 0.1074, 0.9843]]]))\n",
      "(tensor([[[0.7043, 0.6343, 0.3183, 0.1325],\n",
      "         [0.8560, 0.5837, 0.7610, 0.5017]],\n",
      "\n",
      "        [[0.3159, 0.5753, 0.1571, 0.7462],\n",
      "         [0.4330, 0.7616, 0.3375, 0.2553]],\n",
      "\n",
      "        [[0.1288, 0.9278, 0.9681, 0.4022],\n",
      "         [0.2588, 0.1727, 0.5065, 0.4860]],\n",
      "\n",
      "        [[0.9836, 0.0587, 0.5013, 0.2730],\n",
      "         [0.7209, 0.9671, 0.6290, 0.7841]]]), tensor([[[0.0836, 0.1199, 0.6244, 0.4331]],\n",
      "\n",
      "        [[0.4162, 0.1262, 0.4016, 0.1169]],\n",
      "\n",
      "        [[0.4261, 0.2434, 0.5032, 0.9790]],\n",
      "\n",
      "        [[0.4790, 0.7242, 0.1074, 0.9843]]]))\n",
      "(tensor([[[0.7043, 0.6343],\n",
      "         [0.8560, 0.5837],\n",
      "         [0.0836, 0.1199]],\n",
      "\n",
      "        [[0.3159, 0.5753],\n",
      "         [0.4330, 0.7616],\n",
      "         [0.4162, 0.1262]],\n",
      "\n",
      "        [[0.1288, 0.9278],\n",
      "         [0.2588, 0.1727],\n",
      "         [0.4261, 0.2434]],\n",
      "\n",
      "        [[0.9836, 0.0587],\n",
      "         [0.7209, 0.9671],\n",
      "         [0.4790, 0.7242]]]), tensor([[[0.3183, 0.1325],\n",
      "         [0.7610, 0.5017],\n",
      "         [0.6244, 0.4331]],\n",
      "\n",
      "        [[0.1571, 0.7462],\n",
      "         [0.3375, 0.2553],\n",
      "         [0.4016, 0.1169]],\n",
      "\n",
      "        [[0.9681, 0.4022],\n",
      "         [0.5065, 0.4860],\n",
      "         [0.5032, 0.9790]],\n",
      "\n",
      "        [[0.5013, 0.2730],\n",
      "         [0.6290, 0.7841],\n",
      "         [0.1074, 0.9843]]]))\n",
      "(tensor([[[0.7043, 0.6343, 0.3183, 0.1325],\n",
      "         [0.8560, 0.5837, 0.7610, 0.5017],\n",
      "         [0.0836, 0.1199, 0.6244, 0.4331]]]), tensor([[[0.3159, 0.5753, 0.1571, 0.7462],\n",
      "         [0.4330, 0.7616, 0.3375, 0.2553],\n",
      "         [0.4162, 0.1262, 0.4016, 0.1169]],\n",
      "\n",
      "        [[0.1288, 0.9278, 0.9681, 0.4022],\n",
      "         [0.2588, 0.1727, 0.5065, 0.4860],\n",
      "         [0.4261, 0.2434, 0.5032, 0.9790]],\n",
      "\n",
      "        [[0.9836, 0.0587, 0.5013, 0.2730],\n",
      "         [0.7209, 0.9671, 0.6290, 0.7841],\n",
      "         [0.4790, 0.7242, 0.1074, 0.9843]]]))\n",
      "(tensor([[[0.7043, 0.6343, 0.3183, 0.1325]],\n",
      "\n",
      "        [[0.3159, 0.5753, 0.1571, 0.7462]],\n",
      "\n",
      "        [[0.1288, 0.9278, 0.9681, 0.4022]],\n",
      "\n",
      "        [[0.9836, 0.0587, 0.5013, 0.2730]]]), tensor([[[0.8560, 0.5837, 0.7610, 0.5017],\n",
      "         [0.0836, 0.1199, 0.6244, 0.4331]],\n",
      "\n",
      "        [[0.4330, 0.7616, 0.3375, 0.2553],\n",
      "         [0.4162, 0.1262, 0.4016, 0.1169]],\n",
      "\n",
      "        [[0.2588, 0.1727, 0.5065, 0.4860],\n",
      "         [0.4261, 0.2434, 0.5032, 0.9790]],\n",
      "\n",
      "        [[0.7209, 0.9671, 0.6290, 0.7841],\n",
      "         [0.4790, 0.7242, 0.1074, 0.9843]]]))\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(4,3,4)\n",
    "print(torch.chunk(a,2,0))\n",
    "print(torch.chunk(a,2,1))\n",
    "print(torch.chunk(a,3,2))\n",
    "print(torch.split(a,[1,3],0))\n",
    "print(torch.split(a,[1,2],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[0.3215],\n",
      "          [0.2742],\n",
      "          [0.2269]]],\n",
      "\n",
      "\n",
      "        [[[0.9251],\n",
      "          [0.2706],\n",
      "          [0.7992]]],\n",
      "\n",
      "\n",
      "        [[[0.1598],\n",
      "          [0.2628],\n",
      "          [0.8503]]]]),)\n",
      "tensor([[0.3215, 0.2742, 0.2269],\n",
      "        [0.9251, 0.2706, 0.7992],\n",
      "        [0.1598, 0.2628, 0.8503]])\n",
      "tensor([[[0.3215],\n",
      "         [0.2742],\n",
      "         [0.2269]],\n",
      "\n",
      "        [[0.9251],\n",
      "         [0.2706],\n",
      "         [0.7992]],\n",
      "\n",
      "        [[0.1598],\n",
      "         [0.2628],\n",
      "         [0.8503]]])\n",
      "tensor([[[0.3215, 0.9251, 0.1598],\n",
      "         [0.2742, 0.2706, 0.2628],\n",
      "         [0.2269, 0.7992, 0.8503]]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(3,1,3,1,1)\n",
    "print(torch.unbind(a,4))   #删除第四维度\n",
    "b=torch.squeeze(a)      #删除全部多余维度\n",
    "print(b)    \n",
    "b=torch.unsqueeze(b,2)    #增添维度\n",
    "print(b)  \n",
    "print(torch.transpose(b,0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（五）激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15., 15., 15., 15., -4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.,  5.,\n",
      "         6.,  7.,  8.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 2., 3., 4., 5., 6., 7., 8.])\n",
      "tensor([-0.9997, -0.9991, -0.9975, -0.9933, -0.9817, -0.9502, -0.8647, -0.6321,\n",
      "         0.0000,  1.0000,  2.0000,  3.0000,  4.0000,  5.0000,  6.0000,  7.0000,\n",
      "         8.0000])\n",
      "tensor([-0.1600, -0.1400, -0.1200, -0.1000, -0.0800, -0.0600, -0.0400, -0.0200,\n",
      "         0.0000,  1.0000,  2.0000,  3.0000,  4.0000,  5.0000,  6.0000,  7.0000,\n",
      "         8.0000])\n",
      "tensor([3.3535e-04, 9.1105e-04, 2.4726e-03, 6.6929e-03, 1.7986e-02, 4.7426e-02,\n",
      "        1.1920e-01, 2.6894e-01, 5.0000e-01, 7.3106e-01, 8.8080e-01, 9.5257e-01,\n",
      "        9.8201e-01, 9.9331e-01, 9.9753e-01, 9.9909e-01, 9.9966e-01])\n",
      "tensor([-1.0000, -1.0000, -1.0000, -0.9999, -0.9993, -0.9951, -0.9640, -0.7616,\n",
      "         0.0000,  0.7616,  0.9640,  0.9951,  0.9993,  0.9999,  1.0000,  1.0000,\n",
      "         1.0000])\n",
      "tensor([-1., -1., -1., -1., -1., -1., -1., -1.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.])\n",
      "tensor([7.1136e-08, 1.9337e-07, 5.2563e-07, 1.4288e-06, 3.8839e-06, 1.0557e-05,\n",
      "        2.8698e-05, 7.8010e-05, 2.1205e-04, 5.7642e-04, 1.5669e-03, 4.2592e-03,\n",
      "        1.1578e-02, 3.1471e-02, 8.5548e-02, 2.3254e-01, 6.3212e-01])\n",
      "tensor([-16.4587, -15.4587, -14.4587, -13.4587, -12.4587, -11.4587, -10.4587,\n",
      "         -9.4587,  -8.4587,  -7.4587,  -6.4587,  -5.4587,  -4.4587,  -3.4587,\n",
      "         -2.4587,  -1.4587,  -0.4587])\n",
      "tensor([3.3541e-04, 9.1147e-04, 2.4757e-03, 6.7153e-03, 1.8150e-02, 4.8587e-02,\n",
      "        1.2693e-01, 3.1326e-01, 6.9315e-01, 1.3133e+00, 2.1269e+00, 3.0486e+00,\n",
      "        4.0181e+00, 5.0067e+00, 6.0025e+00, 7.0009e+00, 8.0003e+00])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "x=torch.tensor(range(-8,9))\n",
    "x=x.float()\n",
    "f1=nn.Threshold(-5,15)\n",
    "print(f1(x))\n",
    "f2=nn.ReLU()\n",
    "print(f2(x))\n",
    "f3=nn.ELU(1)\n",
    "print(f3(x))\n",
    "f4=nn.LeakyReLU(0.02)   #参数为泄露斜率，默认0.01\n",
    "print(f4(x))\n",
    "f5=nn.Sigmoid()\n",
    "print(f5(x))\n",
    "f6=nn.Tanh()\n",
    "print(f6(x))\n",
    "f7=nn.Hardtanh()    #取绝对值或平方可以当损失函数\n",
    "print(f7(x))\n",
    "f8=nn.Softmax(dim=0)\n",
    "print(f8(x))\n",
    "f9=nn.LogSoftmax(dim=0)\n",
    "print(f9(x))\n",
    "f10=nn.Softplus()\n",
    "print(f10(x))\n",
    "#MaxOut暂时没有实现，Github上可以找到"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（六）损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归问题loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-8., -7., -6., -5., -4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.,  5.,\n",
      "         6.,  7.,  8.])\n",
      "tensor([-8.3612, -6.1148, -5.6255, -6.3858, -5.1459, -3.2029, -3.2986, -1.2185,\n",
      "        -0.1330,  0.8922,  2.3900,  2.1025,  3.4778,  5.8204,  5.3299,  6.9021,\n",
      "         9.0232])\n",
      "tensor([ 0.3612, -0.8852, -0.3745,  1.3858,  1.1459,  0.2029,  1.2986,  0.2185,\n",
      "         0.1330,  0.1078, -0.3900,  0.8975,  0.5222, -0.8204,  0.6701,  0.0979,\n",
      "        -1.0232])\n",
      "tensor(0.6197)\n",
      "tensor(0.5589)\n",
      "tensor(0.6197)\n",
      "tensor(0.5589)\n",
      "tensor(0.2718)\n",
      "tensor(0.2718)\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor(range(-8,9))\n",
    "x=x.float()\n",
    "y=x+torch.randn(17)\n",
    "print(x)\n",
    "print(y)\n",
    "print(x-y)\n",
    "print(torch.mean(torch.abs(x-y)))\n",
    "print(torch.mean((x-y)**2))\n",
    "los1=nn.L1Loss()\n",
    "print(los1(x,y))\n",
    "los2=nn.MSELoss()\n",
    "print(los2(x,y))\n",
    "los3=nn.SmoothL1Loss()\n",
    "print(los3(x,y))\n",
    "los4=nn.HuberLoss()\n",
    "print(los4(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多分类问题Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2])\n",
      "tensor([[-0.9143, -0.0390, -0.4401,  0.7279],\n",
      "        [ 0.6095, -0.4507, -0.8436,  0.4791]])\n",
      "tensor([[-2.3198, -1.4444, -1.8455, -0.6775],\n",
      "        [-0.8993, -1.9596, -2.3524, -1.0297]])\n",
      "tensor(2.3361)\n",
      "tensor(2.3361)\n"
     ]
    }
   ],
   "source": [
    "target=torch.empty(2, dtype=torch.long).random_(4)\n",
    "y = torch.randn(2, 4)\n",
    "print(target)\n",
    "print(y)\n",
    "los5 = nn.NLLLoss()  #要求input为每个分类概率的对数，NLLL求其的负对数和。\n",
    "g1=nn.LogSoftmax(dim=1)\n",
    "input=g1(y)\n",
    "print(input)\n",
    "print(los5(input,target))\n",
    "los6=nn.CrossEntropyLoss()\n",
    "print(los6(y,target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二分类Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 0.])\n",
      "tensor([-2.0321,  0.8872,  0.7734])\n",
      "tensor(1.2176)\n",
      "tensor(1.2177)\n"
     ]
    }
   ],
   "source": [
    "target=torch.empty(3, dtype=torch.long).random_(2)\n",
    "target=target.float()\n",
    "y = torch.randn(3)\n",
    "print(target)\n",
    "print(y)\n",
    "g2=nn.Sigmoid()\n",
    "input=g2(y)\n",
    "los7=nn.BCELoss()\n",
    "print(los7(input,target))\n",
    "los8=nn.BCEWithLogitsLoss()\n",
    "print(los8(y,target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（七）导数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1923, 0.2009, 0.1351],\n",
      "        [0.1923, 0.2009, 0.1351],\n",
      "        [0.1923, 0.2009, 0.1351],\n",
      "        [0.1923, 0.2009, 0.1351],\n",
      "        [0.1923, 0.2009, 0.1351]])\n",
      "tensor([0.1923, 0.2009, 0.1351])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5)  \n",
    "y = torch.zeros(3) \n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（八）优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0.6422, 0.6436, 0.1657], requires_grad=True)]\n",
      "[tensor([0.0249, 0.0254, 0.0007], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as opt\n",
    "y=torch.rand(3,requires_grad=True)\n",
    "y=[y]\n",
    "print(y)\n",
    "loss=torch.mean(y[0]**2)\n",
    "optimizer1=opt.SGD(y,lr=0.01,momentum=0.5)   #默认动量为0\n",
    "optimizer2=opt.Adagrad(y, lr=0.01, lr_decay=0, weight_decay=0)\n",
    "optimizer3=opt.RMSprop(y, lr=0.01, alpha=0.99, weight_decay=0, momentum=0)   #上两种实现了学习率的自我调整\n",
    "optimizer4=opt.Adam(y, lr=0.01, betas=(0.9, 0.999), weight_decay=0)   #结合RMS与动量\n",
    "#第三种与第四种效果较好且常用\n",
    "\n",
    "opter_use=optimizer4\n",
    "for i in range(1,100):\n",
    "    opter_use.zero_grad()\n",
    "    loss=torch.mean(y[0]**2)\n",
    "    loss.backward()\n",
    "    opter_use.step()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（九）torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "tra=datasets.MNIST(root=\"data\",train=True, download=True,transform=transforms.ToTensor())\n",
    "tes=datasets.MNIST(root=\"data\",train=False, download=True,transform=transforms.ToTensor())\n",
    "ima=tra[0][0]\n",
    "tran1=transforms.ToPILImage()\n",
    "ima=tran1(ima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 6, 5, 0, 6, 3, 3, 7, 8, 9, 2, 2, 5, 8, 1, 2, 9, 1, 6, 9, 8, 9, 8, 5,\n",
      "        7, 1, 3, 2, 9, 2, 2, 1, 6, 0, 3, 1, 8, 5, 6, 9, 4, 4, 9, 8, 3, 8, 8, 5,\n",
      "        2, 7, 6, 0, 9, 2, 3, 7, 9, 4, 8, 4, 9, 6, 2, 7])\n",
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "tra_dloader = DataLoader(tra, batch_size=64, shuffle=True)\n",
    "tes_dloader = DataLoader(tes, batch_size=64, shuffle=True)\n",
    "tra_loader_use=iter(tra_dloader)\n",
    "a,b=next(tra_loader_use)\n",
    "print(b)\n",
    "print(a.size())\n",
    "a2=a.squeeze()\n",
    "#print(a2[0])\n",
    "#plt.plot(range(1,11),range(1,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（十）神经网络的创建与操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.func=nn.Linear(13,1)\n",
    "    def forward(self,x):\n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1688, -0.2329, -0.1872, -0.0004,  0.1975,  0.1643,  0.1799, -0.0496,\n",
      "          0.2422, -0.1140, -0.0198,  0.0459,  0.0923]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0335], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "mod=Net()\n",
    "for par in mod.parameters():\n",
    "    print(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('func.weight', Parameter containing:\n",
      "tensor([[-0.1688, -0.2329, -0.1872, -0.0004,  0.1975,  0.1643,  0.1799, -0.0496,\n",
      "          0.2422, -0.1140, -0.0198,  0.0459,  0.0923]], requires_grad=True))\n",
      "('func.bias', Parameter containing:\n",
      "tensor([-0.0335], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for par in mod.named_parameters():\n",
    "    print(par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（十一）神经网络层函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-46b6bc92721a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mm2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "input = torch.randn(32, 1, 5, 5)\n",
    "m1 = nn.Conv2d(1, 32, 5, 1, 1)\n",
    "m2 = nn.Flatten(1,3)\n",
    "output = m1(input)\n",
    "print(output.size())\n",
    "output=m2(output)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 4])\n"
     ]
    }
   ],
   "source": [
    "model=nn.Sequential(nn.Linear(100,20),nn.ReLU(),nn.Linear(20,4))\n",
    "input = torch.randn(45,100)\n",
    "output=model(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 33, 48, 96])\n",
      "torch.Size([20, 33, 24, 96])\n",
      "torch.Size([20, 33, 28, 100])\n",
      "torch.Size([20, 33, 26, 100])\n"
     ]
    }
   ],
   "source": [
    "m1 = nn.Conv2d(16, 33, (3, 5))\n",
    "m2 = nn.Conv2d(16, 33, (3, 5),stride=(2,1))\n",
    "m3 = nn.Conv2d(16, 33, (3, 5),stride=(2,1),padding=(4,2))\n",
    "m4 = nn.Conv2d(16, 33, (3, 5),stride=(2,1),padding=(4,2),dilation=(3,1))\n",
    "input = torch.randn(20, 16, 50, 100)\n",
    "output = m1(input)\n",
    "print(output.shape)\n",
    "output = m2(input)\n",
    "print(output.shape)\n",
    "output = m3(input)\n",
    "print(output.shape)\n",
    "output = m4(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [33, 16, 3, 5], but got 3-dimensional input of size [20, 50, 100] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-e4627c9ee1cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 439\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [33, 16, 3, 5], but got 3-dimensional input of size [20, 50, 100] instead"
     ]
    }
   ],
   "source": [
    "m1 = nn.Conv2d(16, 33, (3, 5))\n",
    "input = torch.randn(20,  50, 100)\n",
    "output = m1(input)\n",
    "print(output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
